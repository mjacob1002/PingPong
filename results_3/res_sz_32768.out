Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.003 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
4.388229 second have elapsed
438822.943000
Time (in nanoseconds): 438822.943000 message_size: 32768 PROTOCOL: Parameter_Marshalling
4.148548 second have elapsed
414854.848600
Time (in nanoseconds): 414854.848600 message_size: 32768 PROTOCOL: Message
4.182768 second have elapsed
418276.841600
Time (in nanoseconds): 418276.841600 message_size: 32768 PROTOCOL: Message_w/o_allocation
[Partition 0][Node 0] End of program
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.021 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
4.439078 second have elapsed
443907.837900
Time (in nanoseconds): 443907.837900 message_size: 32768 PROTOCOL: Parameter_Marshalling
4.156244 second have elapsed
415624.419200
Time (in nanoseconds): 415624.419200 message_size: 32768 PROTOCOL: Message
4.156444 second have elapsed
415644.391600
Time (in nanoseconds): 415644.391600 message_size: 32768 PROTOCOL: Message_w/o_allocation
[Partition 0][Node 0] End of program
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.001 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
4.446494 second have elapsed
444649.374900
Time (in nanoseconds): 444649.374900 message_size: 32768 PROTOCOL: Parameter_Marshalling
4.152174 second have elapsed
415217.365800
Time (in nanoseconds): 415217.365800 message_size: 32768 PROTOCOL: Message
4.178912 second have elapsed
417891.164200
Time (in nanoseconds): 417891.164200 message_size: 32768 PROTOCOL: Message_w/o_allocation
[Partition 0][Node 0] End of program
