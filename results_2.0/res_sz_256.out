Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.024 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
1.995399 second have elapsed
1995.399162
Time per message on each chare: 1995.399162 nanoseconds per message.
[Partition 0][Node 0] End of program
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.001 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
2.026715 second have elapsed
2026.714504
Time per message on each chare: 2026.714504 nanoseconds per message.
[Partition 0][Node 0] End of program
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.022 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
2.030309 second have elapsed
2030.308509
Time per message on each chare: 2030.308509 nanoseconds per message.
[Partition 0][Node 0] End of program
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.023 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
5.677927 second have elapsed
5677.926952
Time (in nanoseconds): 5677.926952 message_size: 256 PROTOCOL: Parameter Marshalling
10.088703 second have elapsed
10088.702803
Time (in nanoseconds): 10088.702803 message_size: 256 PROTOCOL: Message
15.357559 second have elapsed
15357.558611
Time (in nanoseconds): 15357.558611 message_size: 256 PROTOCOL: Message w/o allocation
[Partition 0][Node 0] End of program
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.001 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
5.479011 second have elapsed
5479.010976
Time (in nanoseconds): 5479.010976 message_size: 256 PROTOCOL: Parameter Marshalling
9.865449 second have elapsed
9865.449112
Time (in nanoseconds): 9865.449112 message_size: 256 PROTOCOL: Message
15.063845 second have elapsed
15063.844846
Time (in nanoseconds): 15063.844846 message_size: 256 PROTOCOL: Message w/o allocation
[Partition 0][Node 0] End of program
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.001 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
5.483644 second have elapsed
5483.644333
Time (in nanoseconds): 5483.644333 message_size: 256 PROTOCOL: Parameter Marshalling
9.874511 second have elapsed
9874.510900
Time (in nanoseconds): 9874.510900 message_size: 256 PROTOCOL: Message
15.091330 second have elapsed
15091.330053
Time (in nanoseconds): 15091.330053 message_size: 256 PROTOCOL: Message w/o allocation
[Partition 0][Node 0] End of program
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.024 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
5.513189 second have elapsed
5513.189098
Time (in nanoseconds): 5513.189098 message_size: 256 PROTOCOL: Parameter Marshalling
4.488243 second have elapsed
4488.242749
Time (in nanoseconds): 4488.242749 message_size: 256 PROTOCOL: Message
5.295185 second have elapsed
5295.184880
Time (in nanoseconds): 5295.184880 message_size: 256 PROTOCOL: Message w/o allocation
[Partition 0][Node 0] End of program
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.022 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
5.496724 second have elapsed
5496.724207
Time (in nanoseconds): 5496.724207 message_size: 256 PROTOCOL: Parameter Marshalling
4.460296 second have elapsed
4460.296063
Time (in nanoseconds): 4460.296063 message_size: 256 PROTOCOL: Message
5.256898 second have elapsed
5256.897736
Time (in nanoseconds): 5256.897736 message_size: 256 PROTOCOL: Message w/o allocation
[Partition 0][Node 0] End of program
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_FUNNELED (desired: MPI_THREAD_FUNNELED)
Charm++> Running in SMP mode: 1 processes, 2 worker threads (PEs) + 1 comm threads per process, 2 PEs total
Charm++> The comm. thread both sends and receives messages
Converse/Charm++ Commit ID: v7.1.0-devel-172-ge6d5463bb
CharmLB> Load balancer assumes all CPUs are same.
Charm++> cpu affinity enabled. 
Charm++> cpuaffinity PE-core map (logical indices): 0,1
Charm++> Running on 1 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.001 seconds.
CharmLB> Load balancing instrumentation for communication is off.
LOGISTICS
Number of PEs: 2
Number of nodes: 1
5.498610 second have elapsed
5498.610486
Time (in nanoseconds): 5498.610486 message_size: 256 PROTOCOL: Parameter Marshalling
4.441838 second have elapsed
4441.837878
Time (in nanoseconds): 4441.837878 message_size: 256 PROTOCOL: Message
5.215734 second have elapsed
5215.734188
Time (in nanoseconds): 5215.734188 message_size: 256 PROTOCOL: Message w/o allocation
[Partition 0][Node 0] End of program
